# -*- coding: utf-8 -*-
"""Final Project virtual intership ID/X

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VAp8FC8PVy1gVpWF82NrNFSFzQgqLCNx

# Membaca data

Melakukan load data dan melihat informasi dari data dan menampilkan 5 baris pertama dari data
"""

!pip install dython

import itertools
import joblib
import os

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; sns.set();

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import make_column_selector as selector
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, confusion_matrix
from dython.nominal import associations

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

from imblearn.over_sampling import SMOTE

df = pd.read_csv('loan_data_2007_2014.csv')
# melihat informasi dari data
df.info()

# menampilkan 5 baris pertama dari data
df.head()

"""# Analisis Data

Melihat status peminjaman
"""

def plotcount(df, y, title, **sns_kwargs):
  data = df['loan_status'].value_counts()

  plt.figure(figsize=(16,12))
  plt.title(title, fontsize=20)
  sns.countplot(data = df, y = df['loan_status'], order=data.index, **sns_kwargs)

  percentage = data / data.sum()
  percentage = percentage.apply("{:.2%}".format)

  print(percentage)

plotcount(df, y = 'loan_status', title = "Status Pinjaman")
total_rows = df.count
print(total_rows)

"""Karena current dan in grace period merupakan status yang netral (Tidak termasuk gagal bayar atau berhasil bayar), maka data tersebut kita hapus saja."""

df.drop(df[(df['loan_status'] == "Current")].index, inplace=True)
df.drop(df[(df['loan_status'] == "In Grace Period")].index, inplace = True)
plotcount(df, y = 'loan_status', title = "Status Pinjaman")
total_rows = df.count
print(total_rows)

"""Credit risk yang seharusnya diterima pada waktu yang akan data adalah status peminjamannya "Fully Paid" atau berhasil dilunaskan, sementara yang ditolak adalah pinjaman dengan status charged off, default dan does not meet the credit policy."""

approved =[
    "Fully Paid"
]
dissaproved = [
    "Charged Off",
    "Does not meet the credit policy. Status:Fully Paid",
    "Default",
    "Does not meet the credit policy. Status:Charged Off"
]

"""Kita lakukan standarisasi, dimana jika pinjaman diterima karena statusnya adalah fully paid akan bernilai 1, selain itu bernilai 0"""

def label_loan_status(value):
    if value in approved:
        return 1
    return 0

label_loan_status("Fully Paid")

new_df = df[df["loan_status"].isin(approved + dissaproved)].copy()
new_df["loan_status"] = new_df["loan_status"].apply(label_loan_status)
plotcount(new_df, y="loan_status", title="Status Pinjaman")

"""Dari grafik diatas, dapat dilihat bahwa distribusi data tidak seimbang, sehingga perlu dilakukan data sampling sebelum melakukan pelatihan model machine learning

Selanjutnya kita akan menghapus kolom yang menurut penulis memeliki pengaruh kecil atau tidak berpengaruh dalam penentu keputusan apakah status pinjaman tersebut berhasil dibayar lunas atau tidak.
"""

# Informasi rinci mengenai kolom dan baris data
data_stat = pd.DataFrame()
data_stat.index = new_df.columns
data_stat["unique_value"] = new_df.nunique()
data_stat["missing_rate"] = new_df.isna().mean()
data_stat["dtype"] = new_df.dtypes
data_stat

# Kolom yang tidak terdapat nilai
miss_col = data_stat[data_stat["missing_rate"] == 1].index.to_list()
print("Kolom yang tidak memiliki nilai:")
print(miss_col)
print()

# Kolom yang terlalu unik
vari_col = data_stat[data_stat["unique_value"] == new_df.shape[0]].index.to_list()
print("Kolom yang terlalu unik:")
print(vari_col)
print()

# Kolom dengan kategori yang banyak
cat_col_stat = data_stat[data_stat["dtype"] == "object"]
vari_cat_col = cat_col_stat[cat_col_stat["unique_value"] > 1000].index.to_list()
print("Kolom dengan kategori yang banyak:")
print(vari_cat_col)
print()

# Kolom yang terdiri dari satu nilai
single_valued_col = data_stat[data_stat["unique_value"] == 1].index.to_list()
print("Kolom yang terlalu unik:")
print(single_valued_col)
print()

removed_features = miss_col + vari_col + vari_cat_col + single_valued_col

"""Menghitung korelasi kolom loan_status dengan kolom lainnya untuk mengetahui parameter yang mempengaruhi nilai pada loan_status"""

# Hilangkan fitur yang tidak terpakai
pre_df = new_df.loc[:, ~new_df.columns.isin(removed_features)].copy()
pre_df.info()

"""Mencari fitur numerik yang akan digunakan"""

correlations = (pre_df.select_dtypes(exclude=object)
                         .corr()
                         .dropna(how="all", axis=0)
                         .dropna(how="all", axis=1)
)

data = correlations["loan_status"].abs().sort_values(ascending=False)
data

"""Kita masukkan kolom dengan nilai korelasi lebih dari 0.1 ke dalam dataframe yang akan digunakan untuk pelatihan machine learning"""

a = 0
num_app = []
for i in data.values:
  if i > 0.1 :
    num_app.append(data.index[a])
  a += 1

num_app

# kolom-kolom yang berdata tanggal
date_cols = ["issue_d", "earliest_cr_line", "last_pymnt_d", "last_credit_pull_d", "next_pymnt_d"]

for col in date_cols:
    print(pre_df[col].value_counts().iloc[:5])
    print()

# Korelasi antar tanggal dan status pinjaman
used_cols = date_cols + ["loan_status"] 
complete_correlation = associations(
    pre_df[used_cols], 
    filename='date_correlation.png',
    figsize=(10,10)
)

date_cols_app = ["issue_d", "last_pymnt_d", "last_credit_pull_d", "next_pymnt_d"]

# Kolom-kolom yang berdata kategorik
cat_features = pre_df.select_dtypes(include=object).columns
cat_features

other_cat_cols = cat_features[~cat_features.isin(date_cols)]
other_cat_cols

# Korelasi antar fitur kategorikal dan status pinjaman
used_cols = other_cat_cols.to_list() + ["loan_status"]
complete_correlation = associations(
    pre_df[used_cols], 
    filename='cat_correlation.png',
    figsize=(10,10)
)

#kolom_kategori yang akan dipakai
cat_app = ['term', 'grade', 'sub_grade']

app = num_app + date_cols_app + cat_app
app_df = pre_df[app]

"""Mencari kolom yang terdapat nilai null"""

app_df.isna().mean().sort_values(ascending=False)

"""memasukkan nilai pada kolom yang terdapat data null"""

# kita isi kolom next_pymnt_d, last_pymnt_d dan inq_lat_6mths dengan nilai lunas
# karena terdapat kemungkinan hutang sudah dibayar lunas

app_df["next_pymnt_d"] = app_df["next_pymnt_d"].fillna("lunas")
app_df["last_pymnt_d"] = app_df["last_pymnt_d"].fillna("lunas")
app_df["last_credit_pull_d"] = app_df["last_credit_pull_d"].fillna("lunas")

# kolom inq_last_6months akan diisi dengan nilai modus
mode = app_df["inq_last_6mths"].mode().values[0]
app_df["inq_last_6mths"] = app_df["inq_last_6mths"].fillna(mode)

# cek apakah masih ada kolom yang terdapat nilai null
app_df.isna().mean().sort_values(ascending=False)

"""# Melakukan pemodelan data"""

train_df = app_df

x = train_df.drop(columns = "loan_status")
y = app_df["loan_status"]

num_features = x.select_dtypes(exclude="object")
cat_features = x.select_dtypes(include="object")

# Normalisasi fitur numerik
num_features = (num_features - num_features.mean()) / num_features.std()
num_features

# OneHotEncode fitur kategorik
cat_features = pd.get_dummies(cat_features)
cat_features

# Gabungkan Fitur
features_full = pd.concat([num_features, cat_features], axis=1)
x = features_full

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=1)

"""Melakukan Over sampling menggunakan SMOTE"""

sm = SMOTE(random_state = 2)
x_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())

print("Before OverSampling, counts of label '1': {}".format(sum(y_train == 1)))
print("Before OverSampling, counts of label '0': {} \n".format(sum(y_train == 0)))

print("After OverSampling, counts of label '1': {}".format(sum(y_train_res == 1)))
print("After OverSampling, counts of label '0': {}".format(sum(y_train_res == 0)))

lr1 = LogisticRegression()
lr1.fit(x_train_res, y_train_res.ravel())
predictions = lr1.predict(x_test)
  
# print classification report
print(classification_report(y_test, predictions))

joblib.dump(lr1, "logres.z")
logres = joblib.load("logres.z")

logres.score(x_train, y_train)

report = classification_report(y_true=y_train, y_pred=logres.predict(x_train))
print(report)

logres.score(x_test, y_test)

report = classification_report(y_true=y_test, y_pred=logres.predict(x_test))
print(report)